For my final project for Quantitative Engineering Analysis at Olin College of Engineering, I did a deep dive convolutional neural networks. Throughout this process I created several deliverables, including:

- A problem set (and solution set) for my classmates to learn neural network fundamentals, including terminology, sigmoid functions, multivariable chain rule, and iterative gradient descent. The problem set included provides about 3.5 to 4 hours of material, and starter code in a Jupyter notebook. Here are links for the [lesson plan](https://github.com/hsharriman/QEA/blob/master/reports/QEAHomework.pdf) and [companion notebook](https://github.com/hsharriman/QEA/blob/master/QEA%20Night%20Assignment.ipynb).

- Two separate neural networks, a feedforward ([code](https://github.com/hsharriman/QEA/blob/master/ff2.py)) and a convolutional neural network ([code](https://github.com/hsharriman/QEA/blob/master/CNN.ipynb)), using only Python and Numpy to recognize handwritten digits. In addition to implementing a feedforward and convolutional network, I also implemented dataset pre-processing, batch and epoch capabilities, incremental testing, as well as saving and loading checkpoints.

- A [technical write-up](https://github.com/hsharriman/QEA/blob/master/reports/QEAReport.pdf) detailing the concepts, process, and analysis used throughout the project.

- A presentation introducing my classmates to my project its key outcomes.

This project is meant to be a deep exploration into the math behind neural networks, specifically convolutional neural networks. As such, there is no use of high-level packages such as Pytorch or Tensorflow, since the goal was to understand the math that drives these powerful tools. My implementation was able to achieve 89% accuracy on the test set.

All of the code and materials can be found on Github.
